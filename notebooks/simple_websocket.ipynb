{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7319a8b4",
   "metadata": {},
   "source": [
    "# How to use OpenAI Real Time API with websockets\n",
    "\n",
    "## Architecture\n",
    "\n",
    "1. Thread safe Audio Queue\n",
    "1. Audio recording thread --> Saves to a thread safe Audio Queue\n",
    "2. Asyncronously run two tasks\n",
    "    1. Send messages to websocket: Send Audio data from Audio queue to websocket connection\n",
    "    2. Receive messages from websocket: Receive Transcription events from websocket connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c28802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import queue\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "import websockets\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import base64\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "azure_api_key=os.getenv(\"AZURE_OPENAI_GPT4O_API_KEY\")\n",
    "azure_endpoint=os.getenv(\"AZURE_OPENAI_GPT4O_ENDPOINT\")\n",
    "azure_deployment=os.getenv(\"AZURE_OPENAI_GPT4O_DEPLOYMENT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1f1d4",
   "metadata": {},
   "source": [
    "## Audio Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Queue\n",
    "AUDIO_QUEUE = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_capture(stop_event):\n",
    "    \"\"\"Capture audio from microphone and add to queue\"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "        format=pyaudio.paInt16,  # 16-bit PCM (pcm16)\n",
    "        channels=1,              # Mono audio\n",
    "        rate=24000,              # 24kHz as recommended by OpenAI\n",
    "        input=True,\n",
    "        frames_per_buffer=1024,  # Number of frames per buffer\n",
    "    )\n",
    "\n",
    "    print(\"üéôÔ∏è Recording started...\")\n",
    "\n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            data = stream.read(num_frames=1024, exception_on_overflow=False)\n",
    "            if stop_event.is_set():\n",
    "                break\n",
    "            AUDIO_QUEUE.put(data)\n",
    "    finally:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "        print(\"üéôÔ∏è Recording stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf997917",
   "metadata": {},
   "source": [
    "## Config to start Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"api-key\": azure_api_key}\n",
    "ws_url = f\"wss://{azure_endpoint}/openai/realtime?intent=transcription&deployment={azure_deployment}&api-version=2024-10-01-preview\"\n",
    "\n",
    "config = {\n",
    "    \"type\": \"transcription_session.update\",\n",
    "    \"session\": {\n",
    "        \"input_audio_format\": \"pcm16\",\n",
    "        \"input_audio_transcription\": {\"model\": \"gpt-4o-transcribe\"},\n",
    "        \"turn_detection\": {\n",
    "            \"type\": \"server_vad\",\n",
    "            \"threshold\": 0.5,\n",
    "            \"prefix_padding_ms\": 300,\n",
    "            \"silence_duration_ms\": 500,\n",
    "        },\n",
    "        \"input_audio_noise_reduction\": {\n",
    "            \"type\": \"near_field\"\n",
    "        } # Use no noise reduction for now\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5259b4",
   "metadata": {},
   "source": [
    "## Send Audio and Receive Message tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bfff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def send_audio(websocket, stop_event):\n",
    "    \"\"\"Send audio data to the WebSocket server\"\"\"\n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            if not AUDIO_QUEUE.empty():\n",
    "                audio_data = AUDIO_QUEUE.get()\n",
    "                \n",
    "                # Encode audio data as base64\n",
    "                encoded_data = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "\n",
    "                # Create audio buffer message\n",
    "                message = {\n",
    "                    \"type\": \"input_audio_buffer.append\",\n",
    "                    \"audio\": encoded_data,\n",
    "                }\n",
    "                await websocket.send(json.dumps(message))\n",
    "            await asyncio.sleep(0.01)  # Small delay to prevent busy waiting\n",
    "    except websockets.ConnectionClosed:\n",
    "        print(\"send_audio: WebSocket connection closed\")\n",
    "    except asyncio.CancelledError as e:\n",
    "        print(f\"send_audio: Task cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd412630",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def receive_messages(websocket, stop_event):\n",
    "    \"\"\"Receive messages from the WebSocket server\"\"\"\n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            try:\n",
    "                message = await websocket.recv()\n",
    "                data = json.loads(message)\n",
    "                if \"type\" in data and data[\"type\"] == \"input_audio_buffer.speech_started\":\n",
    "                    print(\"üé§ Speech Detected\")\n",
    "                elif \"type\" in data and data[\"type\"] == \"input_audio_buffer.speech_stopped\":\n",
    "                    print(\"üîáSpeech Stopped\")\n",
    "                elif \"type\" in data and data[\"type\"] == \"conversation.item.input_audio_transcription.completed\":\n",
    "                    # Transcription utterance completed\n",
    "                    transcript_raw = data.get(\"transcript\", \"\")\n",
    "                    transcript_json = json.loads(transcript_raw)\n",
    "                    transcript = transcript_json.get(\"text\", \"\")\n",
    "                    print(f'\\nüìù Azure Completed Transcript: \"{transcript}\"', flush=True)\n",
    "                else:\n",
    "                    pass\n",
    "                    # Implement other message types as needed\n",
    "            except websockets.ConnectionClosed:\n",
    "                print(\"Connection closed\")\n",
    "                break\n",
    "    except asyncio.CancelledError as e:\n",
    "        print(f\"receive_messages: Task cancelled\")\n",
    "    except websockets.ConnectionClosed as e:\n",
    "        print(f\"receive_messages: WebSocket connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67ff7e",
   "metadata": {},
   "source": [
    "## Start transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d200b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear audio queue\n",
    "while not AUDIO_QUEUE.empty():\n",
    "    AUDIO_QUEUE.get()\n",
    "    \n",
    "    \n",
    "stop_event = threading.Event()\n",
    "# This will run the audio capture in a separate thread\n",
    "audio_thread = threading.Thread(target=audio_capture, args=(stop_event,))\n",
    "audio_thread.daemon = True\n",
    "audio_thread.start()\n",
    "    \n",
    "async with websockets.connect(\n",
    "    ws_url, additional_headers=headers\n",
    ") as websocket:\n",
    "    try:\n",
    "        print(\"üîó WebSocket connection established\")\n",
    "        print(\"Speak into the microphone...\")\n",
    "\n",
    "        # Setup the transcription session\n",
    "        await websocket.send(json.dumps(config))\n",
    "        \n",
    "        # Create tasks for sending audio and receiving messages\n",
    "        send_task = asyncio.create_task(send_audio(websocket, stop_event))\n",
    "        receive_task = asyncio.create_task(receive_messages(websocket, stop_event))\n",
    "        \n",
    "        # Wait until any one the task finishes\n",
    "        try:\n",
    "            done, pending = await asyncio.wait(\n",
    "                {send_task, receive_task}, return_when=asyncio.FIRST_COMPLETED\n",
    "            )\n",
    "        except asyncio.CancelledError:\n",
    "            print(\"üõë Stopping...\")\n",
    "        \n",
    "    finally:\n",
    "        if not stop_event.is_set():\n",
    "            stop_event.set()\n",
    "        if audio_thread.is_alive():\n",
    "            audio_thread.join(timeout=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7afb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
